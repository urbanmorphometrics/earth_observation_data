{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import momepy as mm\n",
    "from tqdm import tqdm\n",
    "from momepy import limit_range\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from inequality.theil import Theil\n",
    "import libpysal\n",
    "import scipy as sp\n",
    "import mapclassify\n",
    "import mapclassify.classifiers as classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "blg = gpd.read_parquet('../../nairobi/buildings.pq')\n",
    "streets = gpd.read_parquet('../../nairobi/edges.pq')\n",
    "tess = gpd.read_parquet('../../nairobi/tessellation.pq')\n",
    "blocks = gpd.read_parquet('../../nairobi/blocks.pq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 230978/507532 [00:32<00:39, 7017.49it/s]/opt/conda/lib/python3.8/site-packages/momepy/shape.py:773: RuntimeWarning: invalid value encountered in arccos\n",
      "  angle = np.arccos(cosine_angle)\n",
      "100%|██████████| 507532/507532 [01:14<00:00, 6779.59it/s]\n",
      " 46%|████▌     | 231102/507532 [00:52<01:01, 4523.21it/s]/opt/conda/lib/python3.8/site-packages/momepy/shape.py:862: RuntimeWarning: invalid value encountered in arccos\n",
      "  angle = np.degrees(np.arccos(cosine_angle))\n",
      "100%|██████████| 507532/507532 [01:59<00:00, 4237.94it/s]\n"
     ]
    }
   ],
   "source": [
    "blg['sdbAre'] = mm.Area(blg).series\n",
    "blg['sdbPer'] = mm.Perimeter(blg).series\n",
    "blg['ssbCCo'] = mm.CircularCompactness(blg, 'sdbAre').series\n",
    "blg['ssbCor'] = mm.Corners(blg).series\n",
    "blg['ssbSqu'] = mm.Squareness(blg).series\n",
    "blg['ssbERI'] = mm.EquivalentRectangularIndex(blg, 'sdbAre', 'sdbPer').series\n",
    "blg['ssbElo'] = mm.Elongation(blg).series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 231144/507532 [01:07<01:22, 3366.12it/s]/opt/conda/lib/python3.8/site-packages/momepy/shape.py:1080: RuntimeWarning: invalid value encountered in arccos\n",
      "  angle = np.arccos(cosine_angle)\n",
      "100%|██████████| 507532/507532 [02:32<00:00, 3325.20it/s]\n"
     ]
    }
   ],
   "source": [
    "cencon = mm.CentroidCorners(blg)\n",
    "blg['ssbCCM'] = cencon.mean\n",
    "blg['ssbCCD'] = cencon.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 507532/507532 [02:36<00:00, 3246.59it/s]\n",
      "100%|██████████| 506435/506435 [06:32<00:00, 1290.98it/s]\n"
     ]
    }
   ],
   "source": [
    "blg['stbOri'] = mm.Orientation(blg).series\n",
    "tess['stcOri'] = mm.Orientation(tess).series\n",
    "blg['stbCeA'] = mm.CellAlignment(blg, tess, 'stbOri', 'stcOri', 'uID', 'uID').series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tess['sdcLAL'] = mm.LongestAxisLength(tess).series\n",
    "tess['sdcAre'] = mm.Area(tess).series\n",
    "tess['sscCCo'] = mm.CircularCompactness(tess, 'sdcAre').series\n",
    "tess['sscERI'] = mm.EquivalentRectangularIndex(tess, 'sdcAre').series\n",
    "tess['sicCAR'] = mm.AreaRatio(tess, blg, 'sdcAre', 'sdbAre', 'uID').series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 507532/507532 [03:32<00:00, 2391.48it/s]\n",
      "100%|██████████| 507532/507532 [03:40<00:00, 2304.01it/s]\n",
      "100%|██████████| 506435/506435 [00:04<00:00, 110095.10it/s]\n",
      "100%|██████████| 506435/506435 [01:25<00:00, 5941.44it/s]\n"
     ]
    }
   ],
   "source": [
    "queen_1 = libpysal.weights.contiguity.Queen.from_dataframe(tess, ids=\"uID\", silence_warnings=True)\n",
    " \n",
    "blg[\"mtbAli\"] = mm.Alignment(blg, queen_1, \"uID\", \"stbOri\").series\n",
    "blg[\"mtbNDi\"] = mm.NeighborDistance(blg, queen_1, \"uID\").series\n",
    "tess[\"mtcWNe\"] = mm.Neighbors(tess, queen_1, \"uID\", weighted=True).series\n",
    "tess[\"mdcAre\"] = mm.CoveredArea(tess, queen_1, \"uID\").series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12191/12191 [00:14<00:00, 825.05it/s]\n",
      "100%|██████████| 12191/12191 [00:00<00:00, 96794.87it/s]\n"
     ]
    }
   ],
   "source": [
    "blocks[\"ldkAre\"] = mm.Area(blocks).series\n",
    "blocks[\"ldkPer\"] = mm.Perimeter(blocks).series\n",
    "blocks[\"lskCCo\"] = mm.CircularCompactness(blocks, \"ldkAre\").series\n",
    "blocks[\"lskERI\"] = mm.EquivalentRectangularIndex(blocks, \"ldkAre\", \"ldkPer\").series\n",
    "blocks[\"lskCWA\"] = mm.CompactnessWeightedAxis(blocks, \"ldkAre\", \"ldkPer\").series\n",
    "blocks[\"ltkOri\"] = mm.Orientation(blocks).series\n",
    " \n",
    "blo_q1 = libpysal.weights.contiguity.Queen.from_dataframe(blocks, ids=\"bID\", silence_warnings=True)\n",
    " \n",
    "blocks[\"ltkWNB\"] = mm.Neighbors(blocks, blo_q1, \"bID\", weighted=True).series\n",
    "blocks[\"likWBB\"] = mm.Count(blocks, blg, \"bID\", \"bID\", weighted=True).series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-5b763fe89c32>:1: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
      "  tess.drop(columns='geometry').to_parquet('../../nairobi/tess_data.parquet')\n",
      "<ipython-input-11-5b763fe89c32>:2: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
      "  blg.drop(columns='geometry').to_parquet('../../nairobi/blg_data.parquet')\n",
      "<ipython-input-11-5b763fe89c32>:3: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
      "  blocks.drop(columns='geometry').to_parquet('../../nairobi/blocks_data.parquet')\n"
     ]
    }
   ],
   "source": [
    "tess.drop(columns='geometry').to_parquet('../../nairobi/tess_data.parquet')\n",
    "blg.drop(columns='geometry').to_parquet('../../nairobi/blg_data.parquet')\n",
    "blocks.drop(columns='geometry').to_parquet('../../nairobi/blocks_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 324/507532 [00:00<05:12, 1625.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing mean interbuilding distances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 507532/507532 [08:30<00:00, 994.32it/s] \n",
      "Calculating adjacency: 100%|██████████| 507532/507532 [00:03<00:00, 156483.19it/s]\n"
     ]
    }
   ],
   "source": [
    "queen3 = mm.sw_high(k=3, weights=queen_1)\n",
    "queen1 = queen_1\n",
    "blg_queen = blg_q1\n",
    "\n",
    "blg['ltbIBD'] = mm.MeanInterbuildingDistance(blg, queen1, 'uID', queen3).series\n",
    "blg['ltcBuA'] = mm.BuildingAdjacency(blg, queen3, 'uID', blg_queen).series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 506435/506435 [06:22<00:00, 1325.50it/s]\n"
     ]
    }
   ],
   "source": [
    "tess = tess.merge(blg[['uID']], on='uID', how='left')\n",
    "\n",
    "tess['ltcWRB'] = mm.BlocksCount(tess, 'bID', queen3, 'uID').series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-bd7e78ee6eca>:1: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
      "  tess.drop(columns='geometry').to_parquet('../../nairobi/tess_data.parquet')\n",
      "<ipython-input-14-bd7e78ee6eca>:2: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
      "  blg.drop(columns='geometry').to_parquet('../../nairobi/blg_data.parquet')\n"
     ]
    }
   ],
   "source": [
    "tess.drop(columns='geometry').to_parquet('../../nairobi/tess_data.parquet')\n",
    "blg.drop(columns='geometry').to_parquet('../../nairobi/blg_data.parquet')\n",
    " \n",
    "fo = libpysal.io.open('../../nairobi/queen1.gal', 'w')\n",
    "fo.write(queen1)\n",
    "fo.close()\n",
    " \n",
    "fo = libpysal.io.open('../../nairobi/queen3.gal', 'w')\n",
    "fo.write(queen3)\n",
    "fo.close()\n",
    " \n",
    "fo = libpysal.io.open('../../nairobi/blg_queen.gal', 'w')\n",
    "fo.write(blg_queen)\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1664: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/conda/lib/python3.8/site-packages/momepy/dimension.py:626: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  openness.append(np.isnan(s).sum() / (f).sum())\n",
      "100%|██████████| 115518/115518 [05:14<00:00, 366.90it/s]\n"
     ]
    }
   ],
   "source": [
    "streets[\"sdsLen\"] = mm.Perimeter(streets).series\n",
    "tess[\"stcSAl\"] = mm.StreetAlignment(tess, streets, \"stcOri\", \"nID\").series\n",
    "blg[\"stbSAl\"] = mm.StreetAlignment(blg, streets, \"stbOri\", \"nID\").series\n",
    "\n",
    "profile = mm.StreetProfile(streets, blg, distance=3)\n",
    "streets[\"sdsSPW\"] = profile.w\n",
    "streets[\"sdsSPO\"] = profile.o\n",
    "streets[\"sdsSWD\"] = profile.wd\n",
    " \n",
    "streets[\"sssLin\"] = mm.Linearity(streets).series\n",
    "streets[\"sdsAre\"] = mm.Reached(streets, tess, \"nID\", \"nID\", mode=\"sum\", values=\"sdcAre\").series\n",
    "streets[\"sisBpM\"] = mm.Count(streets, blg, \"nID\", \"nID\", weighted=True).series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-6c060e936c79>:1: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
      "  tess.drop(columns='geometry').to_parquet('../../nairobi/tess_data.parquet')\n",
      "<ipython-input-16-6c060e936c79>:2: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
      "  blg.drop(columns='geometry').to_parquet('../../nairobi/blg_data.parquet')\n",
      "<ipython-input-16-6c060e936c79>:3: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
      "  streets.drop(columns='geometry').to_parquet('../../nairobi/streets_data.parquet')\n"
     ]
    }
   ],
   "source": [
    "tess.drop(columns='geometry').to_parquet('../../nairobi/tess_data.parquet')\n",
    "blg.drop(columns='geometry').to_parquet('../../nairobi/blg_data.parquet')\n",
    "streets.drop(columns='geometry').to_parquet('../../nairobi/streets_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 115518/115518 [00:56<00:00, 2028.26it/s]\n",
      "100%|██████████| 115518/115518 [14:26<00:00, 133.26it/s]\n"
     ]
    }
   ],
   "source": [
    "str_q1 = libpysal.weights.contiguity.Queen.from_dataframe(streets)\n",
    " \n",
    "streets[\"misRea\"] = mm.Reached(\n",
    "    streets, tess, \"nID\", \"nID\", spatial_weights=str_q1, mode=\"count\"\n",
    ").series\n",
    "streets[\"mdsAre\"] = mm.Reached(streets, tess, \"nID\", \"nID\", spatial_weights=str_q1,\n",
    "                               mode=\"sum\").series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node degree\n",
      "subgraph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53367/53367 [01:12<00:00, 739.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cds length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53367/53367 [00:27<00:00, 1938.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering\n",
      "mean_node_dist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53367/53367 [00:00<00:00, 68858.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-5e698dbfc976>:35: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
      "  nodes.to_parquet('../../nairobi/g_nodes.pq')\n",
      "<ipython-input-18-5e698dbfc976>:36: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
      "  edges.to_parquet('../../nairobi/g_edges.pq')\n",
      "100%|██████████| 115518/115518 [00:08<00:00, 13271.10it/s]\n",
      "100%|██████████| 115518/115518 [01:02<00:00, 1846.53it/s]\n",
      "100%|██████████| 115518/115518 [15:55<00:00, 120.89it/s]\n",
      "100%|██████████| 53367/53367 [01:54<00:00, 466.81it/s]\n",
      "100%|██████████| 53367/53367 [02:26<00:00, 364.63it/s]\n",
      "100%|██████████| 507532/507532 [02:50<00:00, 2978.11it/s]\n",
      "100%|██████████| 53367/53367 [00:25<00:00, 2101.79it/s]\n",
      "100%|██████████| 53367/53367 [07:13<00:00, 123.20it/s]\n",
      "100%|██████████| 53367/53367 [02:26<00:00, 365.50it/s]\n",
      "100%|██████████| 53367/53367 [00:24<00:00, 2136.33it/s]\n",
      "100%|██████████| 53367/53367 [04:58<00:00, 178.66it/s]\n"
     ]
    }
   ],
   "source": [
    "graph = mm.gdf_to_nx(streets)\n",
    " \n",
    "print(\"node degree\")\n",
    "graph = mm.node_degree(graph)\n",
    " \n",
    "print(\"subgraph\")\n",
    "graph = mm.subgraph(\n",
    "    graph,\n",
    "    radius=5,\n",
    "    meshedness=True,\n",
    "    cds_length=False,\n",
    "    mode=\"sum\",\n",
    "    degree=\"degree\",\n",
    "    length=\"mm_len\",\n",
    "    mean_node_degree=False,\n",
    "    proportion={0: True, 3: True, 4: True},\n",
    "    cyclomatic=False,\n",
    "    edge_node_ratio=False,\n",
    "    gamma=False,\n",
    "    local_closeness=True,\n",
    "    closeness_weight=\"mm_len\",\n",
    ")\n",
    "print(\"cds length\")\n",
    "graph = mm.cds_length(graph, radius=3, name=\"ldsCDL\")\n",
    " \n",
    "print(\"clustering\")\n",
    "graph = mm.clustering(graph, name=\"xcnSCl\")\n",
    " \n",
    "print(\"mean_node_dist\")\n",
    "graph = mm.mean_node_dist(graph, name=\"mtdMDi\")\n",
    " \n",
    "nodes, edges, sw = mm.nx_to_gdf(graph, spatial_weights=True)\n",
    " \n",
    "print(\"saving\")\n",
    "nodes.to_parquet('../../nairobi/g_nodes.pq')\n",
    "edges.to_parquet('../../nairobi/g_edges.pq')\n",
    " \n",
    "fo = libpysal.io.open('../../nairobi/nodes.gal', \"w\")\n",
    "fo.write(sw)\n",
    "fo.close()\n",
    " \n",
    "edges_w3 = mm.sw_high(k=3, gdf=edges)\n",
    "edges[\"ldsMSL\"] = mm.SegmentsLength(edges, spatial_weights=edges_w3, mean=True).series\n",
    " \n",
    "edges[\"ldsRea\"] = mm.Reached(edges, tess, \"nID\", \"nID\", spatial_weights=edges_w3).series\n",
    "edges[\"ldsRea\"] = mm.Reached(\n",
    "    edges, tess, \"nID\", \"nID\", spatial_weights=edges_w3, mode=\"sum\", values=\"sdcAre\"\n",
    ").series\n",
    " \n",
    "nodes_w5 = mm.sw_high(k=5, weights=sw)\n",
    "nodes[\"lddNDe\"] = mm.NodeDensity(nodes, edges, nodes_w5).series\n",
    "nodes[\"linWID\"] = mm.NodeDensity(\n",
    "    nodes, edges, nodes_w5, weighted=True, node_degree=\"degree\"\n",
    ").series\n",
    " \n",
    "blg[\"nodeID\"] = mm.get_node_id(blg, nodes, edges, \"nodeID\", \"nID\")\n",
    "tess = tess.merge(blg[[\"uID\", \"nodeID\"]], on=\"uID\", how=\"left\")\n",
    " \n",
    "nodes_w3 = mm.sw_high(k=3, weights=sw)\n",
    " \n",
    "nodes[\"lddRea\"] = mm.Reached(nodes, tess, \"nodeID\", \"nodeID\", nodes_w3).series\n",
    "nodes[\"lddARe\"] = mm.Reached(\n",
    "    nodes, tess, \"nodeID\", \"nodeID\", nodes_w3, mode=\"sum\", values=\"sdcAre\"\n",
    ").series\n",
    " \n",
    "nodes[\"sddAre\"] = mm.Reached(\n",
    "    nodes, tess, \"nodeID\", \"nodeID\", mode=\"sum\", values=\"sdcAre\"\n",
    ").series\n",
    "nodes[\"midRea\"] = mm.Reached(nodes, tess, \"nodeID\", \"nodeID\", spatial_weights=sw).series\n",
    "nodes[\"midAre\"] = mm.Reached(\n",
    "    nodes, tess, \"nodeID\", \"nodeID\", spatial_weights=sw, mode=\"sum\", values=\"sdcAre\"\n",
    ").series\n",
    " \n",
    "nodes.rename(\n",
    "    columns={\n",
    "        \"degree\": \"mtdDeg\",\n",
    "        \"meshedness\": \"lcdMes\",\n",
    "        \"local_closeness\": \"lcnClo\",\n",
    "        \"proportion_3\": \"linP3W\",\n",
    "        \"proportion_4\": \"linP4W\",\n",
    "        \"proportion_0\": \"linPDE\",\n",
    "    }, inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-f1c2eb66ab77>:1: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
      "  tess.drop(columns='geometry').to_parquet('../../nairobi/tess_data.parquet')\n",
      "<ipython-input-19-f1c2eb66ab77>:2: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
      "  blg.drop(columns='geometry').to_parquet('../../nairobi/blg_data.parquet')\n",
      "<ipython-input-19-f1c2eb66ab77>:3: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
      "  nodes.drop(columns='geometry').to_parquet('../../nairobi/nodes_data.parquet')\n",
      "<ipython-input-19-f1c2eb66ab77>:4: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
      "  edges.drop(columns='geometry').to_parquet('../../nairobi/edges_data.parquet')\n"
     ]
    }
   ],
   "source": [
    "tess.drop(columns='geometry').to_parquet('../../nairobi/tess_data.parquet')\n",
    "blg.drop(columns='geometry').to_parquet('../../nairobi/blg_data.parquet')\n",
    "nodes.drop(columns='geometry').to_parquet('../../nairobi/nodes_data.parquet')\n",
    "edges.drop(columns='geometry').to_parquet('../../nairobi/edges_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = tess.merge(blg.drop(columns=['nID', 'bID', 'nodeID', 'geometry']), on='uID')\n",
    "merged = merged.merge(blocks.drop(columns='geometry'), on='bID', how='left')\n",
    "merged = merged.merge(edges.drop(columns='geometry'), on='nID', how='left')\n",
    "merged = merged.merge(nodes.drop(columns='geometry'), on='nodeID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-52050a5a525f>:2: UserWarning: this is an initial implementation of Parquet/Feather file support and associated metadata.  This is tracking version 0.1.0 of the metadata specification at https://github.com/geopandas/geo-arrow-spec\n",
      "\n",
      "This metadata specification does not yet make stability promises.  We do not yet recommend using this in a production setting unless you are able to rewrite your Parquet/Feather files.\n",
      "\n",
      "To further ignore this warning, you can do: \n",
      "import warnings; warnings.filterwarnings('ignore', message='.*initial implementation of Parquet.*')\n",
      "  primary.to_parquet('../../nairobi/primary.parquet')\n"
     ]
    }
   ],
   "source": [
    "primary = merged.drop(columns=['nID', 'bID', 'nodeID', 'mm_len', 'cdsbool', 'node_start', 'node_end', 'geometry'])\n",
    "primary.to_parquet('../../nairobi/primary.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theil(y):\n",
    "    y = np.array(y)\n",
    "    n = len(y)\n",
    "    plus = y + np.finfo('float').tiny * (y == 0)  # can't have 0 values\n",
    "    yt = plus.sum(axis=0)\n",
    "    s = plus / (yt * 1.0)\n",
    "    lns = np.log(n * s)\n",
    "    slns = s * lns\n",
    "    t = sum(slns)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _simpson_di(data):\n",
    "\n",
    "    def p(n, N):\n",
    "        if n == 0:\n",
    "            return 0\n",
    "        return float(n) / N\n",
    "\n",
    "    N = sum(data.values())\n",
    "\n",
    "    return sum(p(n, N) ** 2 for n in data.values() if n != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary = pd.read_parquet('../../nairobi/primary.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom = gpd.read_parquet('../../nairobi/tessellation.pq', columns=[\"geometry\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/libpysal/weights/weights.py:172: UserWarning: The weights matrix is not fully connected: \n",
      " There are 139 disconnected components.\n",
      " There are 71 islands with ids: 3010, 11189, 13679, 13825, 14590, 15478, 17987, 19134, 19899, 20722, 20817, 24942, 29564, 32396, 36253, 119727, 164897, 168291, 174530, 174799, 177215, 187304, 188359, 190129, 191485, 334820, 344385, 350734, 364525, 407230, 409817, 410981, 411555, 420979, 430138, 431771, 434375, 439154, 441308, 443173, 443610, 445775, 451986, 454222, 457594, 463478, 475539, 483899, 484682, 488039, 495762, 498974, 500077, 500235, 500353, 500526, 500961, 501305, 501944, 502540, 502814, 502859, 504701, 505683, 505951, 506046, 506228, 506375, 506377, 506413, 506414.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 46s, sys: 1.76 s, total: 1min 47s\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%time queen = libpysal.weights.Queen.from_dataframe(geom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 56s, sys: 1.69 s, total: 1min 57s\n",
      "Wall time: 1min 57s\n"
     ]
    }
   ],
   "source": [
    "%time wk = sum(map(lambda x: queen.sparse ** x, range(2, 11)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 31s, sys: 8.13 s, total: 7min 39s\n",
      "Wall time: 7min 39s\n"
     ]
    }
   ],
   "source": [
    "%time spatial_weights = libpysal.weights.WSP(wk).to_W()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = primary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf.drop(columns=\"highway\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf.fillna(0)  # normally does not happen, but to be sure\n",
    "chars = gdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['uID', 'stcOri', 'sdcLAL', 'sdcAre', 'sscCCo', 'sscERI', 'sicCAR',\n",
       "       'mtcWNe', 'mdcAre', 'ltcWRB', 'stcSAl', 'sdbAre', 'sdbPer', 'ssbCCo',\n",
       "       'ssbCor', 'ssbSqu', 'ssbERI', 'ssbElo', 'ssbCCM', 'ssbCCD', 'stbOri',\n",
       "       'stbCeA', 'mtbAli', 'mtbNDi', 'ltbIBD', 'ltcBuA', 'stbSAl', 'ldkAre',\n",
       "       'ldkPer', 'lskCCo', 'lskERI', 'lskCWA', 'ltkOri', 'ltkWNB', 'likWBB',\n",
       "       'sdsLen', 'sdsSPW', 'sdsSPO', 'sdsSWD', 'sssLin', 'sdsAre', 'sisBpM',\n",
       "       'misRea', 'mdsAre', 'ldsMSL', 'ldsRea', 'mtdDeg', 'lcdMes', 'linP3W',\n",
       "       'linP4W', 'linPDE', 'lcnClo', 'ldsCDL', 'xcnSCl', 'mtdMDi', 'lddNDe',\n",
       "       'linWID', 'lddRea', 'lddARe', 'sddAre', 'midRea', 'midAre'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = ['stcOri', 'sdcLAL', 'sdcAre', 'sscCCo', 'sscERI', 'sicCAR',\n",
    "       'mtcWNe', 'mdcAre', 'ltcWRB', 'sdbAre', 'sdbPer', 'ssbCCo',\n",
    "       'ssbCor', 'ssbSqu', 'ssbERI', 'ssbElo', 'ssbCCM', 'ssbCCD', 'stbOri',\n",
    "       'stbCeA', 'mtbAli', 'mtbNDi', 'ltbIBD', 'ltcBuA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewness = pd.DataFrame(index=chars)\n",
    "for c in chars:\n",
    "    skewness.loc[c, 'skewness'] = sp.stats.skew(gdf[c])\n",
    "headtail = list(skewness.loc[skewness.skewness >= 1].index)\n",
    "to_invert = skewness.loc[skewness.skewness <= -1].index\n",
    "\n",
    "for inv in to_invert:\n",
    "    gdf[inv + '_r'] = gdf[inv].max() - gdf[inv]\n",
    "inverted = [x for x in gdf.columns if '_r' in x]\n",
    "headtail = headtail + inverted\n",
    "natural = [x for x in chars if x not in headtail]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = {}\n",
    "for c in headtail:\n",
    "    bins[c] = mapclassify.HeadTailBreaks(gdf[c]).bins\n",
    "for c in natural:\n",
    "    bins[c] = mapclassify.gadf(gdf[c], method='NaturalBreaks')[1].bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = {}\n",
    "ranges = {}\n",
    "theils = {}\n",
    "simpsons = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ch in gdf.columns:\n",
    "    means[ch] = []\n",
    "    ranges[ch] = []\n",
    "    theils[ch] = []\n",
    "    simpsons[ch] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['lcdMes'] = gdf.apply(\n",
    "            lambda row: row.lcdMes if row.lcdMes >= 0 else 0,\n",
    "            axis=1,\n",
    "        )  # normally does not happen, but to be sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf.round(6)\n",
    "gdf = gdf.set_index('uID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf[chars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/506435 [00:00<?, ?it/s]/opt/conda/lib/python3.8/site-packages/mapclassify/classifiers.py:887: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  gadf = 1 - self.adcm / adam\n",
      "100%|██████████| 506435/506435 [5:23:01<00:00, 26.13it/s]  \n"
     ]
    }
   ],
   "source": [
    "for index in tqdm(range(len(gdf)), total=gdf.shape[0]):\n",
    "    neighbours = [index]\n",
    "    neighbours += spatial_weights.neighbors[index]\n",
    "    \n",
    "    subset = gdf.iloc[neighbours]\n",
    "    for ch in chars:\n",
    "        values_list = subset[ch] \n",
    "        idec = limit_range(values_list, rng=(10, 90))\n",
    "        iquar = limit_range(values_list, rng=(25, 75))\n",
    "        \n",
    "        means[ch].append(np.mean(iquar))\n",
    "        ranges[ch].append(max(iquar) - min(iquar))\n",
    "        theils[ch].append(theil(idec))\n",
    "        \n",
    "        sample_bins = classifiers.UserDefined(values_list, list(bins[ch]))\n",
    "        counts = dict(zip(bins[ch], sample_bins.counts))\n",
    "        simpsons[ch].append(_simpson_di(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextual = pd.DataFrame(index=gdf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stcOri\n",
      "sdcLAL\n",
      "sdcAre\n",
      "sscCCo\n",
      "sscERI\n",
      "sicCAR\n",
      "mtcWNe\n",
      "mdcAre\n",
      "ltcWRB\n",
      "sdbAre\n",
      "sdbPer\n",
      "ssbCCo\n",
      "ssbCor\n",
      "ssbSqu\n",
      "ssbERI\n",
      "ssbElo\n",
      "ssbCCM\n",
      "ssbCCD\n",
      "stbOri\n",
      "stbCeA\n",
      "mtbAli\n",
      "mtbNDi\n",
      "ltbIBD\n",
      "ltcBuA\n"
     ]
    }
   ],
   "source": [
    "for ch in chars:\n",
    "    print(ch)\n",
    "    contextual[ch + '_meanIQ3'] = means[ch]\n",
    "    contextual[ch + '_rangeIQ3'] = ranges[ch]\n",
    "    contextual[ch + '_theilID3'] = theils[ch]\n",
    "    contextual[ch + '_simpson'] = simpsons[ch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextual.to_parquet('../../nairobi/contextual_10.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz(\"../../nairobi/w10.npz\", spatial_weights.sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
